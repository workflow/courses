{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOAA Right Whales Basic Entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Constants and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "from shutil import copyfile\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "import pandas as pd\n",
    "\n",
    "utils_path = os.path.abspath(os.path.join('./utils'))\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CURRENT_DIR = os.getcwd()\n",
    "LESSON_HOME_DIR = CURRENT_DIR\n",
    "DATA_HOME_DIR = CURRENT_DIR + '/data/noaa'\n",
    "TEST_PATH = DATA_HOME_DIR + '/test/' \n",
    "RESULTS_PATH = DATA_HOME_DIR + '/results/'\n",
    "\n",
    "\n",
    "PATH = DATA_HOME_DIR + '/sample/'\n",
    "\n",
    "TRAIN_PATH = PATH + 'train/'\n",
    "VALIDATION_PATH = PATH + 'validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Instantiate plotting tool\n",
    "#In Jupyter notebooks, you will need to run this command before doing any plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_standard_dir_structure():\n",
    "    %cd $DATA_HOME_DIR\n",
    "    %mkdir validation\n",
    "    %mkdir results\n",
    "    # Moving all test images to a class directory of 'unknown', to more easily work with batches\n",
    "    %mkdir -p test/unknown\n",
    "    %mkdir -p sample/train\n",
    "    %mkdir -p sample/test\n",
    "    %mkdir -p sample/validation\n",
    "    %mkdir -p sample/results\n",
    "\n",
    "# TODO: Make directory-agnostic\n",
    "def count_images_in_training_set():\n",
    "    %cd $DATA_HOME_DIR/train\n",
    "    path, dirs, files = os.walk('.').next()\n",
    "    return len(files)\n",
    "\n",
    "# TODO: Make directory-agnostic\n",
    "# TODO: Factor out common stuff\n",
    "def move_training_images_to_validation_set(percent):\n",
    "    total_in_validation_set = int(total_images_in_training_set * (percent / 100.0))\n",
    "\n",
    "    print('Moving {total} from training set to validation set.').format(total=str(total_in_validation_set))\n",
    "\n",
    "    %cd $DATA_HOME_DIR/train\n",
    "    all_training_jpegs = glob('*.jpg')\n",
    "    shuffled_training_jpegs = np.random.permutation(all_training_jpegs)\n",
    "    for i in range(total_in_validation_set):\n",
    "        os.rename(shuffled_training_jpegs[i], DATA_HOME_DIR + '/validation/' + shuffled_training_jpegs[i])\n",
    "\n",
    "# TODO: Make directory-agnostic\n",
    "# TODO: Factor out common stuff\n",
    "def copy_training_images_to_sample(percent):\n",
    "    total_in_sample_training_set = int(total_images_in_training_set * (percent / 100.0))\n",
    "\n",
    "    print('Copying {total} from training set to sample training set.').format(total=str(total_in_sample_training_set))\n",
    "\n",
    "    all_training_jpegs = glob('*.jpg')\n",
    "    shuffled_training_jpegs = np.random.permutation(all_training_jpegs)\n",
    "    for i in range(total_in_sample_training_set):\n",
    "        copyfile(shuffled_training_jpegs[i], DATA_HOME_DIR + '/sample/train/' + shuffled_training_jpegs[i])\n",
    "        \n",
    "# TODO: Make directory-agnostic\n",
    "# TODO: Factor out common stuff\n",
    "def copy_validation_images_to_sample(percent):\n",
    "    %cd $DATA_HOME_DIR/validation\n",
    "    total_in_sample_validation_set = int(total_images_in_training_set * (percent / 100.0))\n",
    "\n",
    "    print('Copying {total} from validation set to sample validation set.').format(total=str(total_in_sample_validation_set))\n",
    "\n",
    "    all_training_jpegs = glob('*.jpg')\n",
    "    shuffled_training_jpegs = np.random.permutation(all_training_jpegs)\n",
    "    for i in range(total_in_sample_validation_set):\n",
    "         copyfile(shuffled_training_jpegs[i], DATA_HOME_DIR + '/sample/validation/' + shuffled_training_jpegs[i])\n",
    "           \n",
    "def split_into_one_directory_per_class(dirs, classes):\n",
    "    for dir in dirs:\n",
    "        %cd $dir\n",
    "        for categoryClass in classes:\n",
    "            %mkdir $categoryClass\n",
    "            %mv {categoryClass}.*.jpg {categoryClass}s/\n",
    "            \n",
    "def move_test_images_to_unknown_category_for_easier_batching():\n",
    "    %cd $TEST_PATH\n",
    "    %mv *.jpg unknown/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Kaggle Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and run the following:\n",
    "\n",
    "```\n",
    "kg config -u farlion -p -c noaa-right-whale-recognition\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://www.kaggle.com/c/noaa-right-whale-recognition/download/sample_submission.csv.zip\n",
      "\n",
      "sample_submission.csv.zip 100% |#####################| Time: 0:00:00  82.4 KiB/s\n",
      "downloading https://www.kaggle.com/c/noaa-right-whale-recognition/download/train.csv.zip\n",
      "\n",
      "train.csv.zip 100% |#################################| Time: 0:00:00  35.4 KiB/s\n",
      "downloading https://www.kaggle.com/c/noaa-right-whale-recognition/download/imgs.zip\n",
      "\n",
      "imgs.zip 100% |######################################| Time: 0:05:31  27.0 MiB/s\n",
      "downloading https://www.kaggle.com/c/noaa-right-whale-recognition/download/w_7489.jpg.zip\n",
      "\n",
      "w_7489.jpg.zip 100% |################################| Time: 0:00:00 756.9 KiB/s\n",
      "downloading https://www.kaggle.com/c/noaa-right-whale-recognition/download/imgs_subset.zip\n",
      "\n",
      "imgs_subset.zip 100% |###############################| Time: 0:00:16  24.0 MiB/s\n"
     ]
    }
   ],
   "source": [
    "!kg download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're placing them into the following structure\n",
    "\n",
    "```\n",
    "utils/\n",
    "    vgg16.py\n",
    "    utils.py\n",
    "lesson1/\n",
    "    redux.ipynb\n",
    "    data/\n",
    "        noaa/\n",
    "            train/\n",
    "                cat.437.jpg\n",
    "                dog.9924.jpg\n",
    "                cat.1029.jpg\n",
    "                dog.4374.jpg\n",
    "            test/\n",
    "                231.jpg\n",
    "                325.jpg\n",
    "                1235.jpg\n",
    "                9923.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!unzip -q sample_submission.csv.zip\n",
    "!unzip -q train.csv.zip\n",
    "!unzip -q imgs.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!rm sample_submission.csv.zip imgs_subset.zip train.csv.zip w_7489.jpg.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir -p data/noaa\n",
    "!mv imgs data/noaa/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Action Plan\n",
    "1. Create Validation and Sample sets\n",
    "2. Rearrange image files into their respective directories \n",
    "3. Finetune and Train model\n",
    "4. Generate predictions\n",
    "5. Validate predictions\n",
    "6. Submit predictions to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training, Validation and Sample sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mv $DATA_HOME_DIR/imgs/* $DATA_HOME_DIR/test/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training Set from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>whaleID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w_7812.jpg</td>\n",
       "      <td>whale_48813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w_4598.jpg</td>\n",
       "      <td>whale_09913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w_3828.jpg</td>\n",
       "      <td>whale_45062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w_8734.jpg</td>\n",
       "      <td>whale_74162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w_3251.jpg</td>\n",
       "      <td>whale_99558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image      whaleID\n",
       "0  w_7812.jpg  whale_48813\n",
       "1  w_4598.jpg  whale_09913\n",
       "2  w_3828.jpg  whale_45062\n",
       "3  w_8734.jpg  whale_74162\n",
       "4  w_3251.jpg  whale_99558"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV\n",
    "training_csv_file = LESSON_HOME_DIR + '/train.csv'\n",
    "training_data_frame = pd.read_csv(training_csv_file)\n",
    "training_data_frame.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>whaleID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4544</td>\n",
       "      <td>4544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4544</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>w_4134.jpg</td>\n",
       "      <td>whale_95370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Image      whaleID\n",
       "count         4544         4544\n",
       "unique        4544          447\n",
       "top     w_4134.jpg  whale_95370\n",
       "freq             1           47"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grab missing image\n",
    "!unzip -q {LESSON_HOME_DIR}/w_7489.jpg.zip\n",
    "!mv w_7489.jpg {TEST_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory '/home/ubuntu/git/courses/deeplearning1/nbs/week-2-assignment/noaa-right-whale-recognition/data/noaa/train/': File exists\r\n"
     ]
    }
   ],
   "source": [
    "%mkdir {DATA_HOME_DIR}/train/\n",
    "training_set_path = DATA_HOME_DIR + '/train/'\n",
    "training_set_images = training_data_frame['Image']\n",
    "training_set_whaleIds = training_data_frame['whaleID']\n",
    "for i in range(len(training_set_images)):\n",
    "    filename_without_extension = os.path.splitext(training_set_images[i])[0]\n",
    "    copyfile(TEST_PATH + training_set_images[i], training_set_path + filename_without_extension + '.' + training_set_whaleIds[i] + '.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/git/courses/deeplearning1/nbs/week-2-assignment/noaa-right-whale-recognition/data/noaa\n",
      "mkdir: cannot create directory 'validation': File exists\n",
      "mkdir: cannot create directory 'results': File exists\n"
     ]
    }
   ],
   "source": [
    "setup_standard_dir_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/git/courses/deeplearning1/nbs/week-2-assignment/noaa-right-whale-recognition/data/noaa/train\n",
      "We have 4544 images in total in our training set.\n"
     ]
    }
   ],
   "source": [
    "total_images_in_training_set = count_images_in_training_set()\n",
    "print('We have {total} images in total in our training set.').format(total=str(total_images_in_training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving 454 from training set to validation set.\n",
      "/home/ubuntu/git/courses/deeplearning1/nbs/week-2-assignment/noaa-right-whale-recognition/data/noaa/train\n"
     ]
    }
   ],
   "source": [
    "move_training_images_to_validation_set(percent=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 45 from training set to sample training set.\n"
     ]
    }
   ],
   "source": [
    "copy_training_images_to_sample(percent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/git/courses/deeplearning1/nbs/week-2-assignment/noaa-right-whale-recognition/data/noaa/validation\n",
      "Copying 11 from validation set to sample validation set.\n"
     ]
    }
   ],
   "source": [
    "copy_validation_images_to_sample(percent=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/git/courses/deeplearning1/nbs/week-2-assignment/noaa-right-whale-recognition/data/noaa/test\n"
     ]
    }
   ],
   "source": [
    "move_test_images_to_unknown_category_for_easier_batching()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split up image files into class directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirs = ['{}/sample/train'.format(DATA_HOME_DIR), \n",
    "        '{}/sample/validation'.format(DATA_HOME_DIR),\n",
    "        '{}/validation'.format(DATA_HOME_DIR),\n",
    "        '{}/train'.format(DATA_HOME_DIR)]\n",
    "classes = ['cats', 'dogs']\n",
    "split_into_one_directory_per_class(dirs=dirs, classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batches = vgg.get_batches(TRAIN_PATH, batch_size=BATCH_SIZE)\n",
    "validation_batches = vgg.get_batches(VALIDATION_PATH, batch_size=BATCH_SIZE)\n",
    "\n",
    "vgg.finetune(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Not sure if we set this for all fits\n",
    "vgg.model.optimizer.lr = LEARNING_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For each epoch we test our model against the validation set\n",
    "latest_weights_filename = None\n",
    "for epoch in range(EPOCHS):\n",
    "    print('Running epoch {}').format(epoch)\n",
    "    vgg.fit(train_batches, validation_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft{}.h5'.format(epoch)\n",
    "    vgg.model.save_weights(RESULTS_PATH + latest_weights_filename)\n",
    "print('Completed {} fit operations').format(EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For every image, vgg.test() generates two probabilities \n",
    "#based on how we've ordered the cats/dogs directories.\n",
    "#It looks like column one is cats and column two is dogs\n",
    "prediction_batches, predictions = vgg.test(TEST_PATH, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(predictions[:5])\n",
    "\n",
    "prediction_filenames = prediction_batches.filenames\n",
    "print(prediction_filenames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can verify the column ordering by viewing some images\n",
    "Image.open(test_path + filenames[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save our test results arrays so we can use them again later\n",
    "save_array(results_path + 'predictions.dat', preds)\n",
    "save_array(results_path + 'prediction_filenames.dat', filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras' *fit()* function conveniently shows us the value of the loss function, and the accuracy, after every epoch (\"*epoch*\" refers to one full run through all training examples). The most important metrics for us to look at are for the validation set, since we want to check for over-fitting. \n",
    "\n",
    "- **Tip**: with our first model we should try to overfit before we start worrying about how to reduce over-fitting - there's no point even thinking about regularization, data augmentation, etc if you're still under-fitting! (We'll be looking at these techniques shortly).\n",
    "\n",
    "As well as looking at the overall metrics, it's also a good idea to look at examples of each of:\n",
    "1. A few correct labels at random\n",
    "2. A few incorrect labels at random\n",
    "3. The most correct labels of each class (ie those with highest probability that are correct)\n",
    "4. The most incorrect labels of each class (ie those with highest probability that are incorrect)\n",
    "5. The most uncertain labels (ie those with probability closest to 0.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we can learn from these examples. (In general, this is a particularly useful technique for debugging problems in the model. However, since this model is so simple, there may not be too much to learn at this stage.)\n",
    "\n",
    "Calculate predictions on validation set, so we can find correct and incorrect examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.load_weights(RESULTS_PATH+latest_weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_batches, validation_probabilities = vgg.test(VALIDATION_PATH, batch_size=BATCH_SIZE)\n",
    "validation_filenames = validation_batches.filenames\n",
    "expected_labels = validation_batches.classes # 0 or 1\n",
    "\n",
    "#Round our predictions to 0/1 to generate labels\n",
    "our_predictions = validation_probabilities[:,0]\n",
    "our_labels = np.round(1-our_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Helper function to plot images by index in the validation set \n",
    "#plots is a helper function in utils.py\n",
    "def plots_idx(idx, titles=None):\n",
    "    plots([image.load_img(valid_path + filenames[i]) for i in idx], titles=titles)\n",
    "    \n",
    "#Number of images to view for each visualization task\n",
    "n_view = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1. A few correct labels at random\n",
    "correct = np.where(our_labels==expected_labels)[0]\n",
    "print \"Found %d correct labels\" % len(correct)\n",
    "idx = permutation(correct)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. A few incorrect labels at random\n",
    "incorrect = np.where(our_labels!=expected_labels)[0]\n",
    "print \"Found %d incorrect labels\" % len(incorrect)\n",
    "idx = permutation(incorrect)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3a. The images we most confident were cats, and are actually cats\n",
    "correct_cats = np.where((our_labels==0) & (our_labels==expected_labels))[0]\n",
    "print \"Found %d confident correct cats labels\" % len(correct_cats)\n",
    "most_correct_cats = np.argsort(our_predictions[correct_cats])[::-1][:n_view]\n",
    "plots_idx(correct_cats[most_correct_cats], our_predictions[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3b. The images we most confident were dogs, and are actually dogs\n",
    "correct_dogs = np.where((our_labels==1) & (our_labels==expected_labels))[0]\n",
    "print \"Found %d confident correct dogs labels\" % len(correct_dogs)\n",
    "most_correct_dogs = np.argsort(our_predictions[correct_dogs])[:n_view]\n",
    "plots_idx(correct_dogs[most_correct_dogs], our_predictions[correct_dogs][most_correct_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4a. The images we were most confident were cats, but are actually dogs\n",
    "incorrect_cats = np.where((our_labels==0) & (our_labels!=expected_labels))[0]\n",
    "print \"Found %d incorrect cats\" % len(incorrect_cats)\n",
    "if len(incorrect_cats):\n",
    "    most_incorrect_cats = np.argsort(our_predictions[incorrect_cats])[::-1][:n_view]\n",
    "    plots_idx(incorrect_cats[most_incorrect_cats], our_predictions[incorrect_cats][most_incorrect_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4b. The images we were most confident were dogs, but are actually cats\n",
    "incorrect_dogs = np.where((our_labels==1) & (our_labels!=expected_labels))[0]\n",
    "print \"Found %d incorrect dogs\" % len(incorrect_dogs)\n",
    "if len(incorrect_dogs):\n",
    "    most_incorrect_dogs = np.argsort(our_predictions[incorrect_dogs])[:n_view]\n",
    "    plots_idx(incorrect_dogs[most_incorrect_dogs], our_predictions[incorrect_dogs][most_incorrect_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5. The most uncertain labels (ie those with probability closest to 0.5).\n",
    "most_uncertain = np.argsort(np.abs(our_predictions-0.5))\n",
    "plots_idx(most_uncertain[:n_view], our_predictions[most_uncertain])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the most common way to analyze the result of a classification model is to use a [confusion matrix](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/). Scikit-learn has a convenient function we can use for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can just print out the confusion matrix, or we can show a graphical view (which is mainly useful for dependents with a larger number of categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Predictions to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the format Kaggle requires for new submissions:\n",
    "```\n",
    "imageId,isDog\n",
    "1242, .3984\n",
    "3947, .1000\n",
    "4539, .9082\n",
    "2345, .0000\n",
    "```\n",
    "\n",
    "Kaggle wants the imageId followed by the probability of the image being a dog. Kaggle uses a metric called [Log Loss](http://wiki.fast.ai/index.php/Log_Loss) to evaluate your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load our test predictions from file\n",
    "preds = load_array(results_path + 'test_preds.dat')\n",
    "filenames = load_array(results_path + 'filenames.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grab the dog prediction column\n",
    "isdog = preds[:,1]\n",
    "print \"Raw Predictions: \" + str(isdog[:5])\n",
    "print \"Mid Predictions: \" + str(isdog[(isdog < .6) & (isdog > .4)])\n",
    "print \"Edge Predictions: \" + str(isdog[(isdog == 1) | (isdog == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#So to play it safe, we use a sneaky trick to round down our edge predictions\n",
    "#Swap all ones with .95 and all zeros with .05\n",
    "isdog = isdog.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract imageIds from the filenames in our test/unknown directory \n",
    "filenames = batches.filenames\n",
    "ids = np.array([int(f[8:f.find('.')]) for f in filenames])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we join the two columns into an array of [imageId, isDog]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = np.stack([ids,isdog], axis=1)\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "submission_file_name = 'submission1.csv'\n",
    "np.savetxt(submission_file_name, subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "%cd $LESSON_HOME_DIR\n",
    "FileLink('data/redux/'+submission_file_name)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
